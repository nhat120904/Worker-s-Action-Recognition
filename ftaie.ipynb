{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:17:01.987379Z",
     "start_time": "2024-11-21T04:17:01.957375Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-18T23:36:46.491366Z",
     "iopub.status.busy": "2024-11-18T23:36:46.490656Z",
     "iopub.status.idle": "2024-11-18T23:36:46.507151Z",
     "shell.execute_reply": "2024-11-18T23:36:46.506235Z",
     "shell.execute_reply.started": "2024-11-18T23:36:46.491330Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "torch.manual_seed(0)\n",
    "COUNT = [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "def calculate_motion_features_df(df):\n",
    "    feature_list = []\n",
    "\n",
    "    # Helper function to extract x, y, z data for a body part\n",
    "    def get_data(body_part, data_type):\n",
    "        return df[[f\"{body_part} x_{data_type}\", \n",
    "                   f\"{body_part} y_{data_type}\", \n",
    "                   f\"{body_part} z_{data_type}\"]].to_numpy()\n",
    "\n",
    "    # Process each row of the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        features = {}\n",
    "\n",
    "        # 1. Energy of Motion: sum of squared acceleration components\n",
    "        def calc_energy(body_part):\n",
    "            accel = row[[f\"{body_part} x_acce\", f\"{body_part} y_acce\", f\"{body_part} z_acce\"]].values\n",
    "            return np.sum(accel ** 2)\n",
    "\n",
    "        features['right_hand_energy'] = calc_energy('Right Hand')\n",
    "        features['left_hand_energy'] = calc_energy('Left Hand')\n",
    "\n",
    "        # 2. Movement Intensity: RMS of acceleration components\n",
    "        def calc_intensity(body_part):\n",
    "            accel = row[[f\"{body_part} x_acce\", f\"{body_part} y_acce\", f\"{body_part} z_acce\"]].values\n",
    "            return np.sqrt(np.mean(accel ** 2))\n",
    "\n",
    "        features['right_hand_intensity'] = calc_intensity('Right Hand')\n",
    "        features['left_hand_intensity'] = calc_intensity('Left Hand')\n",
    "\n",
    "        # 3. Hand-Arm Angle: Angle between hand and forearm acceleration vectors\n",
    "        def calc_segment_angle(part1, part2):\n",
    "            vec1 = row[[f\"{part1} x_acce\", f\"{part1} y_acce\", f\"{part1} z_acce\"]].values\n",
    "            vec2 = row[[f\"{part2} x_acce\", f\"{part2} y_acce\", f\"{part2} z_acce\"]].values\n",
    "            dot_product = np.dot(vec1, vec2)\n",
    "            magnitudes = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "            return np.arccos(np.clip(dot_product / magnitudes, -1.0, 1.0)) * 180.0 / np.pi if magnitudes != 0 else 0\n",
    "\n",
    "        features['right_hand_arm_angle'] = calc_segment_angle('Right Hand', 'Right Forearm')\n",
    "        features['left_hand_arm_angle'] = calc_segment_angle('Left Hand', 'Left Forearm')\n",
    "\n",
    "        # 4. Wrist Rotation: Norm of cross product of hand and forearm acceleration vectors\n",
    "        def calc_wrist_rotation(hand, forearm):\n",
    "            hand_accel = row[[f\"{hand} x_acce\", f\"{hand} y_acce\", f\"{hand} z_acce\"]].values\n",
    "            forearm_accel = row[[f\"{forearm} x_acce\", f\"{forearm} y_acce\", f\"{forearm} z_acce\"]].values\n",
    "            return np.linalg.norm(np.cross(hand_accel, forearm_accel))\n",
    "\n",
    "        features['right_wrist_rotation'] = calc_wrist_rotation('Right Hand', 'Right Forearm')\n",
    "        features['left_wrist_rotation'] = calc_wrist_rotation('Left Hand', 'Left Forearm')\n",
    "\n",
    "        # 5. Hands Symmetry: Norm of difference between left and right hand accelerations\n",
    "        def calc_symmetry(part1, part2):\n",
    "            accel1 = row[[f\"{part1} x_acce\", f\"{part1} y_acce\", f\"{part1} z_acce\"]].values\n",
    "            accel2 = row[[f\"{part2} x_acce\", f\"{part2} y_acce\", f\"{part2} z_acce\"]].values\n",
    "            return np.linalg.norm(accel1 - accel2)\n",
    "\n",
    "        features['hands_symmetry'] = calc_symmetry('Right Hand', 'Left Hand')\n",
    "\n",
    "        # 6. Posture Stability: Variance of accelerations across trunk sensors\n",
    "        def calc_stability():\n",
    "            trunk_parts = ['Pelvis', 'L5', 'L3', 'T12', 'T8']\n",
    "            accels = np.array([row[[f\"{part} x_acce\", f\"{part} y_acce\", f\"{part} z_acce\"]].values for part in trunk_parts])\n",
    "            return np.var(accels)\n",
    "\n",
    "        features['posture_stability'] = calc_stability()\n",
    "\n",
    "        # 7. Movement Efficiency: Ratio of direct path to actual path\n",
    "        def calc_efficiency(body_part):\n",
    "            accel = row[[f\"{body_part} x_acce\", f\"{body_part} y_acce\", f\"{body_part} z_acce\"]].values\n",
    "            direct_path = np.linalg.norm(accel)\n",
    "            actual_path = np.sum(np.abs(accel))\n",
    "            return direct_path / actual_path if actual_path != 0 else 1\n",
    "\n",
    "        features['right_hand_efficiency'] = calc_efficiency('Right Hand')\n",
    "        features['left_hand_efficiency'] = calc_efficiency('Left Hand')\n",
    "\n",
    "        # 8. Kinetic Power: Dot product of acceleration and velocity (proxy for power)\n",
    "        def calc_kinetic_power(body_part):\n",
    "            accel = row[[f\"{body_part} x_acce\", f\"{body_part} y_acce\", f\"{body_part} z_acce\"]].values\n",
    "            velocity = row[[f\"{body_part} x\", f\"{body_part} y\", f\"{body_part} z\"]].values\n",
    "            return np.sum(accel * velocity)\n",
    "\n",
    "        features['right_hand_kinetic_power'] = calc_kinetic_power('Right Hand')\n",
    "        features['left_hand_kinetic_power'] = calc_kinetic_power('Left Hand')\n",
    "\n",
    "        feature_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(feature_list)\n",
    "\n",
    "def categorize_sharpness(sharpness):\n",
    "    if sharpness >= 85:\n",
    "        return 0\n",
    "    elif 70 <= sharpness < 85:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2    \n",
    "\n",
    "def extract_and_categorize_sharpness(filename):\n",
    "    # Extract sharpness value using regex (assumes sharpness is the number before the last dash)\n",
    "    sharpness_value = int(re.search(r'-([0-9]+)-', filename).group(1))\n",
    "    return categorize_sharpness(sharpness_value)\n",
    "\n",
    "def split_to_chunk(df, frame_size=60, step=5):\n",
    "    # Check and remove any unnecessary columns\n",
    "    df = df.drop(columns=['Unnamed: 0', 'Frame', 'Marker', 'Frame_acce'], errors='ignore')\n",
    "    # df[\"test\"] = 0\n",
    "    # df = df.drop(columns=['Frame', 'Marker', 'Frame_acce'], errors='ignore')\n",
    "    # motion_features_df = calculate_motion_features_df(df)\n",
    "\n",
    "    if 'Label' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'Label' column\")\n",
    "\n",
    "    # Split into chunks based on changes in label value\n",
    "    chunks = []\n",
    "    current_chunk = [df.iloc[0]]\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        if df['Label'].iloc[i] == df['Label'].iloc[i - 1]:\n",
    "            current_chunk.append(df.iloc[i])\n",
    "        else:\n",
    "            chunks.append(pd.DataFrame(current_chunk))\n",
    "            current_chunk = [df.iloc[i]]\n",
    "            # display(pd.DataFrame(current_chunk))\n",
    "    chunks.append(pd.DataFrame(current_chunk))  # Append the last chunk\n",
    "\n",
    "    # print(\"Total chunks:\", len(chunks))\n",
    "\n",
    "    samples, labels = [], []\n",
    "    # output_dir = \"chunk_output\"\n",
    "    \n",
    "    # Iterate through each chunk and create samples\n",
    "    for chunk_idx, chunk in enumerate(chunks):\n",
    "        # print label of chunks\n",
    "        # print(\"chunk label\", chunk['Label'].iloc[0])\n",
    "        # add to COUNT\n",
    "        # COUNT[int(chunk['Label'].iloc[0])] += 1\n",
    "        if len(chunk) >= frame_size:\n",
    "            for start in range(0, len(chunk) - frame_size + 1, step):\n",
    "                sample = chunk[start:start + frame_size]\n",
    "                samples.append(sample.drop(columns=['Label']))\n",
    "                labels.append(sample['Label'].iloc[0])  # Use the first label in the sample\n",
    "\n",
    "    # print(\"Generated samples:\", len(samples), \"Generated labels:\", len(labels))\n",
    "    # print(\"labels\", labels)\n",
    "    return samples, labels\n",
    "\n",
    "\n",
    "class ActivityDataset(Dataset):\n",
    "    def __init__(self, root, scaler=None):\n",
    "        self.root = root\n",
    "        self.scaler = scaler\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "        \n",
    "        for file in tqdm(os.listdir(self.root)):\n",
    "            if file.endswith(\".csv\"):  # Ensure only CSV files are processed\n",
    "                # print(f\"Processing {file}\")\n",
    "                df = pd.read_csv(os.path.join(self.root, file))\n",
    "                try:\n",
    "                    samples, labels = split_to_chunk(df)\n",
    "                    self.data.extend(samples)\n",
    "                    self.label.extend(labels)\n",
    "                except ValueError as e:\n",
    "                    print(file)\n",
    "                # labels = [extract_and_categorize_sharpness(file)] * len(samples)\n",
    "                # self.label.extend(labels)\n",
    "        \n",
    "        # Normalize data if a scaler is provided\n",
    "        if self.scaler is not None:\n",
    "            self.data = [self.scaler.transform(sample) for sample in self.data]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Convert DataFrame to NumPy array and then to a PyTorch tensor\n",
    "        features = torch.tensor(self.data[idx].to_numpy(), dtype=torch.float32)\n",
    "        label = torch.tensor(self.label[idx], dtype=torch.long)\n",
    "        return features, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:19:52.949127Z",
     "start_time": "2024-11-21T04:17:02.176421Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T23:36:47.241621Z",
     "iopub.status.busy": "2024-11-18T23:36:47.241263Z",
     "iopub.status.idle": "2024-11-18T23:39:02.268938Z",
     "shell.execute_reply": "2024-11-18T23:39:02.268041Z",
     "shell.execute_reply.started": "2024-11-18T23:36:47.241583Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = ActivityDataset(root=\"./processed_data\")\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:20:36.620426Z",
     "start_time": "2024-11-21T04:20:36.609919Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Flatten each sample in the dataset\n",
    "X = [sample.to_numpy().flatten() for sample in dataset.data]  # Features\n",
    "y = dataset.label  # Labels\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming y_val and y_pred are defined\n",
    "report_dict = classification_report(y_val, y_pred, output_dict=True)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "report_df = pd.DataFrame(report_dict).transpose()\n",
    "\n",
    "# Display the DataFrame\n",
    "display(report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'RF_knife_processed_activity.pkl')\n",
    "\n",
    "# Load the model (when needed)\n",
    "# loaded_model = joblib.load('traditional_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:20:58.987280Z",
     "start_time": "2024-11-21T04:20:58.958280Z"
    }
   },
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:20:59.994470Z",
     "start_time": "2024-11-21T04:20:59.922862Z"
    }
   },
   "outputs": [],
   "source": [
    "label_df.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:21:08.788113Z",
     "start_time": "2024-11-21T04:21:08.760504Z"
    }
   },
   "outputs": [],
   "source": [
    "COUNT = [label_df[label_df[0] == i].count().values[0] for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:21:09.584770Z",
     "start_time": "2024-11-21T04:21:09.577770Z"
    }
   },
   "outputs": [],
   "source": [
    "COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:21:13.248574Z",
     "start_time": "2024-11-21T04:21:13.157066Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T23:39:02.270652Z",
     "iopub.status.busy": "2024-11-18T23:39:02.270383Z",
     "iopub.status.idle": "2024-11-18T23:39:02.282599Z",
     "shell.execute_reply": "2024-11-18T23:39:02.281632Z",
     "shell.execute_reply.started": "2024-11-18T23:39:02.270626Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "# Split sizes\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders for training and validation sets\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T04:21:19.813398Z",
     "start_time": "2024-11-21T04:21:19.155236Z"
    },
    "execution": {
     "iopub.execute_input": "2024-11-18T23:39:02.283985Z",
     "iopub.status.busy": "2024-11-18T23:39:02.283725Z",
     "iopub.status.idle": "2024-11-18T23:39:02.294913Z",
     "shell.execute_reply": "2024-11-18T23:39:02.294040Z",
     "shell.execute_reply.started": "2024-11-18T23:39:02.283960Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_classes: int,\n",
    "        num_heads: int = 8,\n",
    "        num_layers: int = 3,\n",
    "        dim_feedforward: int = 256,\n",
    "        dropout: float = 0.1,\n",
    "        max_seq_length: int = 60\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hidden_dim % num_heads == 0, f\"hidden_dim ({hidden_dim}) must be divisible by num_heads ({num_heads})\"\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, hidden_dim)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_dim)  # Layer norm is preferred over batch norm for transformers\n",
    "        \n",
    "        # Improved positional encoding with register_buffer instead of Parameter\n",
    "        position = torch.arange(max_seq_length).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, hidden_dim, 2) * (-math.log(10000.0) / hidden_dim))\n",
    "        pe = torch.zeros(1, max_seq_length, hidden_dim)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pos_embedding', pe)\n",
    "        \n",
    "        # Add dropout after input embedding\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=True  # Important for newer PyTorch versions\n",
    "        )\n",
    "        \n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Add layer norm before final classification\n",
    "        self.final_layer_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x shape: [batch_size, seq_len, input_dim]\n",
    "        \n",
    "        # Input embedding\n",
    "        x = self.linear(x)\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = x + self.pos_embedding[:, :x.size(1)]\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Transformer layers\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # Global average pooling and classification\n",
    "        x = x.mean(dim=1)  # [batch_size, hidden_dim]\n",
    "        x = self.final_layer_norm(x)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T23:39:02.296827Z",
     "iopub.status.busy": "2024-11-18T23:39:02.296587Z",
     "iopub.status.idle": "2024-11-18T23:39:02.318030Z",
     "shell.execute_reply": "2024-11-18T23:39:02.317260Z",
     "shell.execute_reply.started": "2024-11-18T23:39:02.296803Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Print the label distribution first\n",
    "print(\"Label distribution:\", COUNT)\n",
    "\n",
    "# Calculate class weights with protection against zero\n",
    "def calculate_class_weights(count_list):\n",
    "    total_samples = sum(count_list)\n",
    "    # Add a small epsilon to avoid division by zero\n",
    "    weights = [total_samples/(len(count_list) * (c + 1e-6)) if c == 0 else total_samples/(len(count_list) * c) \n",
    "              for c in count_list]\n",
    "    print(weights)\n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128, num_classes=9):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.2,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        features = lstm_out.mean(dim=1)\n",
    "        return self.fc(features)\n",
    "\n",
    "def train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    class_weights,\n",
    "    num_epochs=50,\n",
    "    lr=1e-3,\n",
    "    weight_decay=0.01,\n",
    "    patience=7,\n",
    "    log_dir='./runs'\n",
    "):\n",
    "    # If log_dir not found\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        epoch_preds = []\n",
    "        \n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for features, labels in progress_bar:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            epoch_preds.extend(preds.cpu().numpy())\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_correct += (preds == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "            \n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'acc': f\"{train_correct/train_total:.4f}\",\n",
    "                'preds': f\"{preds[:8]}\",\n",
    "            })\n",
    "        \n",
    "        # Monitor prediction distribution\n",
    "        pred_dist = np.bincount(epoch_preds, minlength=len(COUNT))\n",
    "        # print(\"\\nPrediction distribution:\", pred_dist)\n",
    "        # print(\"Actual distribution:\", COUNT)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_preds = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for features, labels in val_loader:\n",
    "                features, labels = features.to(device), labels.to(device)\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                _, preds = torch.max(outputs, dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_loss += loss.item()\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        val_acc = val_correct / val_total\n",
    "        scheduler.step(val_acc)\n",
    "        \n",
    "        # Print detailed metrics\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_correct/train_total:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        print(\"Validation prediction distribution:\", np.bincount(val_preds, minlength=len(COUNT)))\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"{log_dir}/best_model.pt\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "                break\n",
    "\n",
    "        torch.save(model.state_dict(), f\"{log_dir}/last_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T23:39:02.319393Z",
     "iopub.status.busy": "2024-11-18T23:39:02.319116Z",
     "iopub.status.idle": "2024-11-18T23:47:04.665808Z",
     "shell.execute_reply": "2024-11-18T23:47:04.664564Z",
     "shell.execute_reply.started": "2024-11-18T23:39:02.319365Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the model and start training\n",
    "class_weights = calculate_class_weights(COUNT)\n",
    "print(\"\\nClass weights:\", class_weights)\n",
    "\n",
    "first_features, _ = dataset[0]\n",
    "input_dim = first_features.shape[1]\n",
    "\n",
    "model = LSTMClassifier(\n",
    "    input_dim=input_dim,\n",
    "    hidden_dim=64,\n",
    "    num_classes=len(COUNT)\n",
    ")\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    input_dim=152,          # feature dimension\n",
    "    hidden_dim=256,         # embedding size\n",
    "    num_classes=len(COUNT),\n",
    "    num_heads=8,            # number of heads\n",
    "    num_layers=3,\n",
    "    dim_feedforward=512,    # feed-forward dimension\n",
    "    dropout=0.1,\n",
    "    max_seq_length=60      # sequence length\n",
    ")\n",
    "\n",
    "# model.load_state_dict(torch.load('/kaggle/working/runs/simple_model/best_model.pt'))\n",
    "\n",
    "config = {\n",
    "    'num_epochs': 100,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 0.01,\n",
    "    'patience': 7,\n",
    "    'log_dir': './runs/lstm_knife_raw'\n",
    "}\n",
    "\n",
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    "    class_weights=class_weights.to('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    num_epochs=config['num_epochs'],\n",
    "    lr=config['learning_rate'],\n",
    "    weight_decay=config['weight_decay'],\n",
    "    patience=config['patience'],\n",
    "    log_dir=config['log_dir']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, val_loader, class_weights=None):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights) if class_weights is not None else nn.CrossEntropyLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "    print(f\"\\nValidation Loss: {val_loss / len(val_loader):.4f}\")\n",
    "    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "    print(\"Validation Prediction Distribution:\", np.bincount(val_preds, minlength=len(COUNT)))\n",
    "    print(\"Validation True Label Distribution:\", np.bincount(val_labels, minlength=len(COUNT)))\n",
    "\n",
    "    return val_acc, val_preds, val_labels\n",
    "\n",
    "model = TransformerClassifier(\n",
    "    input_dim=152,          # Your feature dimension\n",
    "    hidden_dim=256,         # Increased embedding size\n",
    "    num_classes=len(COUNT),\n",
    "    num_heads=8,            # Increased number of heads\n",
    "    num_layers=3,\n",
    "    dim_feedforward=512,    # Increased feed-forward dimension\n",
    "    dropout=0.1,\n",
    "    max_seq_length=60      # Your sequence length\n",
    ")\n",
    "\n",
    "# model = SimpleActivityClassifier(\n",
    "#     input_dim=input_dim,\n",
    "#     hidden_dim=64,\n",
    "#     num_classes=len(COUNT)\n",
    "# )\n",
    "\n",
    "state_dict = torch.load('./weights/trans_256_512.pt')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "# Evaluate the model on the validation set\n",
    "val_acc, val_preds, val_labels = evaluate_model(model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Calculate accuracy per class\n",
    "class_accuracies = {}\n",
    "for class_label in set(val_labels):\n",
    "    class_indices = [i for i, label in enumerate(val_labels) if label == class_label]\n",
    "    class_correct = sum([1 for i in class_indices if val_preds[i] == val_labels[i]])\n",
    "    class_accuracies[class_label] = class_correct / len(class_indices)\n",
    "\n",
    "# Convert to DataFrame\n",
    "accuracy_df = pd.DataFrame(list(class_accuracies.items()), columns=['Class', 'Accuracy'])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(accuracy_df)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, classification_report\n",
    "\n",
    "# Calculate precision, recall, and support for each class\n",
    "precision_per_class = {}\n",
    "recall_per_class = {}\n",
    "support_per_class = {}\n",
    "\n",
    "for class_label in set(val_labels):\n",
    "    class_indices = [i for i, label in enumerate(val_labels) if label == class_label]\n",
    "    true_positives = sum([1 for i in class_indices if val_preds[i] == val_labels[i]])\n",
    "    predicted_positives = sum([1 for i, pred in enumerate(val_preds) if pred == class_label])\n",
    "    actual_positives = len(class_indices)\n",
    "    \n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0.0\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0.0\n",
    "    \n",
    "    precision_per_class[class_label] = precision\n",
    "    recall_per_class[class_label] = recall\n",
    "    support_per_class[class_label] = actual_positives\n",
    "\n",
    "# Convert to DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': precision_per_class.keys(),\n",
    "    'Accuracy': [class_accuracies[c] for c in precision_per_class.keys()],\n",
    "    'Precision': precision_per_class.values(),\n",
    "    'Recall': recall_per_class.values(),\n",
    "    'Support': support_per_class.values(),\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "display(metrics_df)\n",
    "\n",
    "# Alternatively, use sklearn classification_report for detailed metrics\n",
    "report = classification_report(val_labels, val_preds, target_names=[str(cls) for cls in set(val_labels)], output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "display(report_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def permutation_importance(model, dataloader, device, feature_idx):\n",
    "    \"\"\"\n",
    "    Calculate the permutation importance of a feature.\n",
    "    :param model: Trained PyTorch model\n",
    "    :param dataloader: DataLoader for evaluation data\n",
    "    :param device: Device to run the model on ('cpu' or 'cuda')\n",
    "    :param feature_idx: Index of the feature to permute\n",
    "    :return: Drop in accuracy after permutation\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    original_preds, permuted_preds, true_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Original predictions\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            original_preds.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Permute the feature\n",
    "            permuted_inputs = inputs.clone()\n",
    "            permuted_inputs[:, :, feature_idx] = permuted_inputs[:, :, feature_idx][torch.randperm(inputs.size(0))]\n",
    "            \n",
    "            # Predictions after permutation\n",
    "            permuted_outputs = model(permuted_inputs)\n",
    "            _, permuted_preds_batch = torch.max(permuted_outputs, dim=1)\n",
    "            permuted_preds.extend(permuted_preds_batch.cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy\n",
    "    original_acc = accuracy_score(true_labels, original_preds)\n",
    "    permuted_acc = accuracy_score(true_labels, permuted_preds)\n",
    "\n",
    "    importance = original_acc - permuted_acc\n",
    "    print(f\"Original Accuracy: {original_acc:.4f}, Permuted Accuracy: {permuted_acc:.4f}, Importance: {importance:.4f}\")\n",
    "    return importance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage with the permutation importance method\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "feature_idx = 20  # Index of the new feature\n",
    "importance = permutation_importance(model, val_dataloader, device, feature_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Get some samples from the validation dataloader\n",
    "test_samples, test_labels = next(iter(val_dataloader))\n",
    "\n",
    "# Move the samples to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "test_samples, test_labels = test_samples.to(device), test_labels.to(device)\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(test_samples)\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "# Print the predictions and the actual labels\n",
    "print(\"Predictions:\", preds.cpu().numpy())\n",
    "print(\"Actual labels:\", test_labels.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6096832,
     "sourceId": 9920388,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "comb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
